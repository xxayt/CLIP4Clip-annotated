2024-09-13 10:12:43,142:INFO: Effective parameters:
2024-09-13 10:12:43,142:INFO: device: cuda:2 n_gpu: 4
2024-09-13 10:12:43,142:INFO: device: cuda:1 n_gpu: 4
2024-09-13 10:12:43,143:INFO:   <<< batch_size: 128
2024-09-13 10:12:43,143:INFO:   <<< batch_size_val: 16
2024-09-13 10:12:43,143:INFO:   <<< cache_dir: 
2024-09-13 10:12:43,143:INFO:   <<< coef_lr: 0.001
2024-09-13 10:12:43,143:INFO:   <<< cross_model: cross-base
2024-09-13 10:12:43,143:INFO: device: cuda:3 n_gpu: 4
2024-09-13 10:12:43,143:INFO:   <<< cross_num_hidden_layers: 4
2024-09-13 10:12:43,143:INFO:   <<< data_path: /home/xinzijie/Projects/CLIP4Clip-annotated/datasets/msvd_data_origin
2024-09-13 10:12:43,143:INFO:   <<< datatype: msvd
2024-09-13 10:12:43,143:INFO:   <<< do_eval: False
2024-09-13 10:12:43,143:INFO:   <<< do_lower_case: False
2024-09-13 10:12:43,143:INFO:   <<< do_pretrain: False
2024-09-13 10:12:43,143:INFO:   <<< do_train: True
2024-09-13 10:12:43,143:INFO:   <<< epochs: 5
2024-09-13 10:12:43,143:INFO:   <<< eval_frame_order: 0
2024-09-13 10:12:43,143:INFO:   <<< expand_msrvtt_sentences: False
2024-09-13 10:12:43,143:INFO:   <<< feature_framerate: 1
2024-09-13 10:12:43,143:INFO:   <<< features_path: /home/xinzijie/VisualSearch/msvd/ImageData
2024-09-13 10:12:43,144:INFO:   <<< fp16: False
2024-09-13 10:12:43,144:INFO:   <<< fp16_opt_level: O1
2024-09-13 10:12:43,144:INFO:   <<< freeze_layer_num: 0
2024-09-13 10:12:43,144:INFO:   <<< gradient_accumulation_steps: 1
2024-09-13 10:12:43,144:INFO:   <<< hard_negative_rate: 0.5
2024-09-13 10:12:43,144:INFO:   <<< init_model: None
2024-09-13 10:12:43,144:INFO:   <<< linear_patch: 2d
2024-09-13 10:12:43,144:INFO:   <<< local_rank: 0
2024-09-13 10:12:43,144:INFO:   <<< loose_type: True
2024-09-13 10:12:43,144:INFO:   <<< lr: 0.0001
2024-09-13 10:12:43,144:INFO:   <<< lr_decay: 0.9
2024-09-13 10:12:43,144:INFO:   <<< margin: 0.1
2024-09-13 10:12:43,144:INFO:   <<< max_frames: 12
2024-09-13 10:12:43,144:INFO:   <<< max_words: 32
2024-09-13 10:12:43,144:INFO:   <<< n_display: 50
2024-09-13 10:12:43,144:INFO:   <<< n_gpu: 1
2024-09-13 10:12:43,144:INFO:   <<< n_pair: 1
2024-09-13 10:12:43,144:INFO:   <<< name: seqTransf_vit32
2024-09-13 10:12:43,144:INFO:   <<< negative_weighting: 1
2024-09-13 10:12:43,144:INFO:   <<< num_thread_reader: 8
2024-09-13 10:12:43,144:INFO:   <<< output_dir: logs
2024-09-13 10:12:43,144:INFO:   <<< path_log: logs/msvd/seqTransf_vit32
2024-09-13 10:12:43,145:INFO:   <<< pretrained_clip_name: ViT-B/32
2024-09-13 10:12:43,145:INFO:   <<< rank: 0
2024-09-13 10:12:43,145:INFO:   <<< resume_model: None
2024-09-13 10:12:43,145:INFO:   <<< sampled_use_mil: False
2024-09-13 10:12:43,145:INFO:   <<< seed: 42
2024-09-13 10:12:43,145:INFO:   <<< sim_header: seqTransf
2024-09-13 10:12:43,145:INFO:   <<< slice_framepos: 2
2024-09-13 10:12:43,145:INFO:   <<< task_type: retrieval
2024-09-13 10:12:43,145:INFO:   <<< text_num_hidden_layers: 12
2024-09-13 10:12:43,145:INFO:   <<< train_csv: data/.train.csv
2024-09-13 10:12:43,145:INFO:   <<< train_frame_order: 0
2024-09-13 10:12:43,145:INFO:   <<< use_mil: False
2024-09-13 10:12:43,145:INFO:   <<< val_csv: data/.val.csv
2024-09-13 10:12:43,145:INFO:   <<< video_dim: 1024
2024-09-13 10:12:43,145:INFO:   <<< visual_num_hidden_layers: 12
2024-09-13 10:12:43,145:INFO:   <<< warmup_proportion: 0.1
2024-09-13 10:12:43,145:INFO:   <<< world_size: 4
2024-09-13 10:12:43,145:INFO: device: cuda:0 n_gpu: 4
2024-09-13 10:12:45,535:INFO: loading archive file /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base
2024-09-13 10:12:45,552:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-09-13 10:12:45,553:INFO: Weight doesn't exsits. /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base/cross_pytorch_model.bin
2024-09-13 10:12:45,553:WARNING: Stage-One:True, Stage-Two:False
2024-09-13 10:12:45,553:WARNING: Test retrieval by loose type.
2024-09-13 10:12:45,553:WARNING: 	 embed_dim: 512
2024-09-13 10:12:45,553:WARNING: 	 image_resolution: 224
2024-09-13 10:12:45,553:WARNING: 	 vision_layers: 12
2024-09-13 10:12:45,553:WARNING: 	 vision_width: 768
2024-09-13 10:12:45,553:WARNING: 	 vision_patch_size: 32
2024-09-13 10:12:45,553:WARNING: 	 context_length: 77
2024-09-13 10:12:45,553:WARNING: 	 vocab_size: 49408
2024-09-13 10:12:45,553:WARNING: 	 transformer_width: 512
2024-09-13 10:12:45,553:WARNING: 	 transformer_heads: 8
2024-09-13 10:12:45,554:WARNING: 	 transformer_layers: 12
2024-09-13 10:12:45,554:WARNING: 		 linear_patch: 2d
2024-09-13 10:12:45,554:WARNING: 	 cut_top_layer: 0
2024-09-13 10:12:47,446:WARNING: 	 sim_header: seqTransf
2024-09-13 10:12:52,223:INFO: --------------------
2024-09-13 10:12:52,223:INFO: Weights from pretrained model not used in CLIP4Clip: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2024-09-13 10:12:55,875:INFO: ***** Running test *****
2024-09-13 10:12:55,875:INFO:   Num examples = 27763
2024-09-13 10:12:55,875:INFO:   Batch size = 16
2024-09-13 10:12:55,875:INFO:   Num steps = 1736
2024-09-13 10:12:55,875:INFO: ***** Running val *****
2024-09-13 10:12:55,875:INFO:   Num examples = 4290
2024-09-13 10:12:56,799:INFO: ***** Running training *****
2024-09-13 10:12:56,799:INFO:   Num examples = 48774
2024-09-13 10:12:56,800:INFO:   Batch size = 128
2024-09-13 10:12:56,800:INFO:   Num steps = 1905
2024-09-13 10:14:09,339:INFO: Epoch: 1/5, Step: 50/381, Lr: 0.000000026-0.000026247, Loss: 1.194055, Time/step: 1.450022
2024-09-13 10:14:59,149:INFO: Epoch: 1/5, Step: 100/381, Lr: 0.000000052-0.000052493, Loss: 0.898039, Time/step: 0.996201
2024-09-13 10:15:49,801:INFO: Epoch: 1/5, Step: 150/381, Lr: 0.000000079-0.000078740, Loss: 0.795905, Time/step: 1.013027
2024-09-13 10:16:39,677:INFO: Epoch: 1/5, Step: 200/381, Lr: 0.000000097-0.000097305, Loss: 0.755921, Time/step: 0.997521
2024-09-13 10:17:30,249:INFO: Epoch: 1/5, Step: 250/381, Lr: 0.000000096-0.000095810, Loss: 0.459234, Time/step: 1.011433
2024-09-13 10:18:20,250:INFO: Epoch: 1/5, Step: 300/381, Lr: 0.000000094-0.000094005, Loss: 0.561311, Time/step: 1.000001
2024-09-13 10:19:10,203:INFO: Epoch: 1/5, Step: 350/381, Lr: 0.000000092-0.000091900, Loss: 0.580929, Time/step: 0.999057
2024-09-13 10:19:38,786:INFO: Epoch 1/5 Finished, Train Loss: 0.878348
2024-09-13 10:19:41,359:INFO: Model saved to logs/msvd/seqTransf_vit32/pytorch_model.bin.0
2024-09-13 10:19:41,359:INFO: Optimizer saved to logs/msvd/seqTransf_vit32/pytorch_opt.bin.0
2024-09-13 10:19:41,365:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-13 10:19:41,365:WARNING: sentence num: 27763, video num: 670
2024-09-13 11:55:19,154:INFO: device: cuda:1 n_gpu: 4
2024-09-13 11:55:19,154:INFO: Effective parameters:
2024-09-13 11:55:19,155:INFO:   <<< batch_size: 128
2024-09-13 11:55:19,155:INFO:   <<< batch_size_val: 16
2024-09-13 11:55:19,155:INFO:   <<< cache_dir: 
2024-09-13 11:55:19,155:INFO: device: cuda:2 n_gpu: 4
2024-09-13 11:55:19,155:INFO:   <<< coef_lr: 0.001
2024-09-13 11:55:19,155:INFO: device: cuda:3 n_gpu: 4
2024-09-13 11:55:19,155:INFO:   <<< cross_model: cross-base
2024-09-13 11:55:19,155:INFO:   <<< cross_num_hidden_layers: 4
2024-09-13 11:55:19,155:INFO:   <<< data_path: /home/xinzijie/Projects/CLIP4Clip-annotated/datasets/msvd_data_origin
2024-09-13 11:55:19,155:INFO:   <<< datatype: msvd
2024-09-13 11:55:19,155:INFO:   <<< do_eval: False
2024-09-13 11:55:19,155:INFO:   <<< do_lower_case: False
2024-09-13 11:55:19,155:INFO:   <<< do_pretrain: False
2024-09-13 11:55:19,155:INFO:   <<< do_train: True
2024-09-13 11:55:19,155:INFO:   <<< epochs: 5
2024-09-13 11:55:19,155:INFO:   <<< eval_frame_order: 0
2024-09-13 11:55:19,155:INFO:   <<< expand_msrvtt_sentences: False
2024-09-13 11:55:19,155:INFO:   <<< feature_framerate: 1
2024-09-13 11:55:19,155:INFO:   <<< features_path: /home/xinzijie/VisualSearch/msvd/ImageData
2024-09-13 11:55:19,156:INFO:   <<< fp16: False
2024-09-13 11:55:19,156:INFO:   <<< fp16_opt_level: O1
2024-09-13 11:55:19,156:INFO:   <<< freeze_layer_num: 0
2024-09-13 11:55:19,156:INFO:   <<< gradient_accumulation_steps: 1
2024-09-13 11:55:19,156:INFO:   <<< hard_negative_rate: 0.5
2024-09-13 11:55:19,156:INFO:   <<< init_model: None
2024-09-13 11:55:19,156:INFO:   <<< linear_patch: 2d
2024-09-13 11:55:19,156:INFO:   <<< local_rank: 0
2024-09-13 11:55:19,156:INFO:   <<< loose_type: True
2024-09-13 11:55:19,156:INFO:   <<< lr: 0.0001
2024-09-13 11:55:19,156:INFO:   <<< lr_decay: 0.9
2024-09-13 11:55:19,156:INFO:   <<< margin: 0.1
2024-09-13 11:55:19,156:INFO:   <<< max_frames: 12
2024-09-13 11:55:19,156:INFO:   <<< max_words: 32
2024-09-13 11:55:19,156:INFO:   <<< n_display: 50
2024-09-13 11:55:19,156:INFO:   <<< n_gpu: 1
2024-09-13 11:55:19,156:INFO:   <<< n_pair: 1
2024-09-13 11:55:19,157:INFO:   <<< name: seqTransf_vit32
2024-09-13 11:55:19,157:INFO:   <<< negative_weighting: 1
2024-09-13 11:55:19,157:INFO:   <<< num_thread_reader: 8
2024-09-13 11:55:19,157:INFO:   <<< output_dir: logs
2024-09-13 11:55:19,157:INFO:   <<< path_log: logs/msvd/seqTransf_vit32
2024-09-13 11:55:19,157:INFO:   <<< pretrained_clip_name: ViT-B/32
2024-09-13 11:55:19,157:INFO:   <<< rank: 0
2024-09-13 11:55:19,157:INFO:   <<< resume_model: None
2024-09-13 11:55:19,157:INFO:   <<< sampled_use_mil: False
2024-09-13 11:55:19,157:INFO:   <<< seed: 42
2024-09-13 11:55:19,157:INFO:   <<< sim_header: seqTransf
2024-09-13 11:55:19,157:INFO:   <<< slice_framepos: 2
2024-09-13 11:55:19,157:INFO:   <<< task_type: retrieval
2024-09-13 11:55:19,157:INFO:   <<< text_num_hidden_layers: 12
2024-09-13 11:55:19,157:INFO:   <<< train_csv: data/.train.csv
2024-09-13 11:55:19,157:INFO:   <<< train_frame_order: 0
2024-09-13 11:55:19,157:INFO:   <<< use_mil: False
2024-09-13 11:55:19,157:INFO:   <<< val_csv: data/.val.csv
2024-09-13 11:55:19,157:INFO:   <<< video_dim: 1024
2024-09-13 11:55:19,158:INFO:   <<< visual_num_hidden_layers: 12
2024-09-13 11:55:19,158:INFO:   <<< warmup_proportion: 0.1
2024-09-13 11:55:19,158:INFO:   <<< world_size: 4
2024-09-13 11:55:19,158:INFO: device: cuda:0 n_gpu: 4
2024-09-13 11:55:21,404:INFO: loading archive file /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base
2024-09-13 11:55:21,405:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-09-13 11:55:21,406:INFO: Weight doesn't exsits. /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base/cross_pytorch_model.bin
2024-09-13 11:55:21,406:WARNING: Stage-One:True, Stage-Two:False
2024-09-13 11:55:21,406:WARNING: Test retrieval by loose type.
2024-09-13 11:55:21,406:WARNING: 	 embed_dim: 512
2024-09-13 11:55:21,407:WARNING: 	 image_resolution: 224
2024-09-13 11:55:21,407:WARNING: 	 vision_layers: 12
2024-09-13 11:55:21,407:WARNING: 	 vision_width: 768
2024-09-13 11:55:21,407:WARNING: 	 vision_patch_size: 32
2024-09-13 11:55:21,407:WARNING: 	 context_length: 77
2024-09-13 11:55:21,407:WARNING: 	 vocab_size: 49408
2024-09-13 11:55:21,407:WARNING: 	 transformer_width: 512
2024-09-13 11:55:21,407:WARNING: 	 transformer_heads: 8
2024-09-13 11:55:21,407:WARNING: 	 transformer_layers: 12
2024-09-13 11:55:21,407:WARNING: 		 linear_patch: 2d
2024-09-13 11:55:21,407:WARNING: 	 cut_top_layer: 0
2024-09-13 11:55:23,231:WARNING: 	 sim_header: seqTransf
2024-09-13 11:55:27,801:INFO: --------------------
2024-09-13 11:55:27,801:INFO: Weights from pretrained model not used in CLIP4Clip: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2024-09-13 11:55:30,780:INFO: ***** Running test *****
2024-09-13 11:55:30,780:INFO:   Num examples = 27763
2024-09-13 11:55:30,780:INFO:   Batch size = 16
2024-09-13 11:55:30,780:INFO:   Num steps = 1736
2024-09-13 11:55:30,780:INFO: ***** Running val *****
2024-09-13 11:55:30,780:INFO:   Num examples = 4290
2024-09-13 11:55:31,469:INFO: ***** Running training *****
2024-09-13 11:55:31,469:INFO:   Num examples = 48774
2024-09-13 11:55:31,469:INFO:   Batch size = 128
2024-09-13 11:55:31,469:INFO:   Num steps = 1905
2024-09-13 11:56:32,880:INFO: Epoch: 1/5, Step: 50/381, Lr: 0.000000026-0.000026247, Loss: 1.194055, Time/step: 1.226903
2024-09-13 11:57:22,407:INFO: Epoch: 1/5, Step: 100/381, Lr: 0.000000052-0.000052493, Loss: 0.898039, Time/step: 0.990523
2024-09-13 11:58:11,169:INFO: Epoch: 1/5, Step: 150/381, Lr: 0.000000079-0.000078740, Loss: 0.795905, Time/step: 0.975224
2024-09-13 11:59:00,440:INFO: Epoch: 1/5, Step: 200/381, Lr: 0.000000097-0.000097305, Loss: 0.755921, Time/step: 0.985408
2024-09-13 11:59:49,891:INFO: Epoch: 1/5, Step: 250/381, Lr: 0.000000096-0.000095810, Loss: 0.459234, Time/step: 0.989025
2024-09-13 12:00:39,592:INFO: Epoch: 1/5, Step: 300/381, Lr: 0.000000094-0.000094005, Loss: 0.561311, Time/step: 0.993997
2024-09-13 12:01:29,132:INFO: Epoch: 1/5, Step: 350/381, Lr: 0.000000092-0.000091900, Loss: 0.580929, Time/step: 0.990806
2024-09-13 12:01:57,537:INFO: Epoch 1/5 Finished, Train Loss: 0.878348
2024-09-13 12:02:00,482:INFO: Model saved to logs/msvd/seqTransf_vit32/pytorch_model.bin.0
2024-09-13 12:02:00,484:INFO: Optimizer saved to logs/msvd/seqTransf_vit32/pytorch_opt.bin.0
2024-09-13 12:02:00,497:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-13 12:02:00,497:WARNING: sentence num: 27763, video num: 670
2024-09-13 13:48:12,754:INFO: device: cuda:3 n_gpu: 4
2024-09-13 13:48:12,764:INFO: device: cuda:1 n_gpu: 4
2024-09-13 13:48:12,764:INFO: device: cuda:2 n_gpu: 4
2024-09-13 13:48:12,764:INFO: Effective parameters:
2024-09-13 13:48:12,765:INFO:   <<< batch_size: 128
2024-09-13 13:48:12,765:INFO:   <<< batch_size_val: 16
2024-09-13 13:48:12,765:INFO:   <<< cache_dir: 
2024-09-13 13:48:12,765:INFO:   <<< coef_lr: 0.001
2024-09-13 13:48:12,765:INFO:   <<< cross_model: cross-base
2024-09-13 13:48:12,765:INFO:   <<< cross_num_hidden_layers: 4
2024-09-13 13:48:12,765:INFO:   <<< data_path: /home/xinzijie/Projects/CLIP4Clip-annotated/datasets/msvd_data_origin
2024-09-13 13:48:12,765:INFO:   <<< datatype: msvd
2024-09-13 13:48:12,765:INFO:   <<< do_eval: False
2024-09-13 13:48:12,765:INFO:   <<< do_lower_case: False
2024-09-13 13:48:12,765:INFO:   <<< do_pretrain: False
2024-09-13 13:48:12,765:INFO:   <<< do_train: True
2024-09-13 13:48:12,765:INFO:   <<< epochs: 5
2024-09-13 13:48:12,765:INFO:   <<< eval_frame_order: 0
2024-09-13 13:48:12,765:INFO:   <<< expand_msrvtt_sentences: False
2024-09-13 13:48:12,765:INFO:   <<< feature_framerate: 1
2024-09-13 13:48:12,765:INFO:   <<< features_path: /home/xinzijie/VisualSearch/msvd/ImageData
2024-09-13 13:48:12,765:INFO:   <<< fp16: False
2024-09-13 13:48:12,765:INFO:   <<< fp16_opt_level: O1
2024-09-13 13:48:12,765:INFO:   <<< freeze_layer_num: 0
2024-09-13 13:48:12,766:INFO:   <<< gradient_accumulation_steps: 1
2024-09-13 13:48:12,766:INFO:   <<< hard_negative_rate: 0.5
2024-09-13 13:48:12,766:INFO:   <<< init_model: None
2024-09-13 13:48:12,766:INFO:   <<< linear_patch: 2d
2024-09-13 13:48:12,766:INFO:   <<< local_rank: 0
2024-09-13 13:48:12,766:INFO:   <<< loose_type: True
2024-09-13 13:48:12,766:INFO:   <<< lr: 0.0001
2024-09-13 13:48:12,766:INFO:   <<< lr_decay: 0.9
2024-09-13 13:48:12,766:INFO:   <<< margin: 0.1
2024-09-13 13:48:12,766:INFO:   <<< max_frames: 12
2024-09-13 13:48:12,766:INFO:   <<< max_words: 32
2024-09-13 13:48:12,766:INFO:   <<< n_display: 50
2024-09-13 13:48:12,766:INFO:   <<< n_gpu: 1
2024-09-13 13:48:12,766:INFO:   <<< n_pair: 1
2024-09-13 13:48:12,766:INFO:   <<< name: seqTransf_vit32
2024-09-13 13:48:12,766:INFO:   <<< negative_weighting: 1
2024-09-13 13:48:12,766:INFO:   <<< num_thread_reader: 8
2024-09-13 13:48:12,766:INFO:   <<< output_dir: logs
2024-09-13 13:48:12,766:INFO:   <<< path_log: logs/msvd/seqTransf_vit32
2024-09-13 13:48:12,766:INFO:   <<< pretrained_clip_name: ViT-B/32
2024-09-13 13:48:12,766:INFO:   <<< rank: 0
2024-09-13 13:48:12,766:INFO:   <<< resume_model: None
2024-09-13 13:48:12,767:INFO:   <<< sampled_use_mil: False
2024-09-13 13:48:12,767:INFO:   <<< seed: 42
2024-09-13 13:48:12,767:INFO:   <<< sim_header: seqTransf
2024-09-13 13:48:12,767:INFO:   <<< slice_framepos: 2
2024-09-13 13:48:12,767:INFO:   <<< task_type: retrieval
2024-09-13 13:48:12,767:INFO:   <<< text_num_hidden_layers: 12
2024-09-13 13:48:12,767:INFO:   <<< train_csv: data/.train.csv
2024-09-13 13:48:12,767:INFO:   <<< train_frame_order: 0
2024-09-13 13:48:12,767:INFO:   <<< use_mil: False
2024-09-13 13:48:12,767:INFO:   <<< val_csv: data/.val.csv
2024-09-13 13:48:12,767:INFO:   <<< video_dim: 1024
2024-09-13 13:48:12,767:INFO:   <<< visual_num_hidden_layers: 12
2024-09-13 13:48:12,767:INFO:   <<< warmup_proportion: 0.1
2024-09-13 13:48:12,767:INFO:   <<< world_size: 4
2024-09-13 13:48:12,767:INFO: device: cuda:0 n_gpu: 4
2024-09-13 13:48:14,975:INFO: loading archive file /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base
2024-09-13 13:48:14,977:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-09-13 13:48:14,977:INFO: Weight doesn't exsits. /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base/cross_pytorch_model.bin
2024-09-13 13:48:14,977:WARNING: Stage-One:True, Stage-Two:False
2024-09-13 13:48:14,977:WARNING: Test retrieval by loose type.
2024-09-13 13:48:14,978:WARNING: 	 embed_dim: 512
2024-09-13 13:48:14,978:WARNING: 	 image_resolution: 224
2024-09-13 13:48:14,978:WARNING: 	 vision_layers: 12
2024-09-13 13:48:14,978:WARNING: 	 vision_width: 768
2024-09-13 13:48:14,978:WARNING: 	 vision_patch_size: 32
2024-09-13 13:48:14,978:WARNING: 	 context_length: 77
2024-09-13 13:48:14,978:WARNING: 	 vocab_size: 49408
2024-09-13 13:48:14,978:WARNING: 	 transformer_width: 512
2024-09-13 13:48:14,978:WARNING: 	 transformer_heads: 8
2024-09-13 13:48:14,978:WARNING: 	 transformer_layers: 12
2024-09-13 13:48:14,978:WARNING: 		 linear_patch: 2d
2024-09-13 13:48:14,978:WARNING: 	 cut_top_layer: 0
2024-09-13 13:48:16,795:WARNING: 	 sim_header: seqTransf
2024-09-13 13:48:21,399:INFO: --------------------
2024-09-13 13:48:21,399:INFO: Weights from pretrained model not used in CLIP4Clip: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2024-09-13 13:48:24,348:INFO: ***** Running test *****
2024-09-13 13:48:24,349:INFO:   Num examples = 27763
2024-09-13 13:48:24,349:INFO:   Batch size = 16
2024-09-13 13:48:24,349:INFO:   Num steps = 1736
2024-09-13 13:48:24,349:INFO: ***** Running val *****
2024-09-13 13:48:24,349:INFO:   Num examples = 4290
2024-09-13 13:48:25,025:INFO: ***** Running training *****
2024-09-13 13:48:25,025:INFO:   Num examples = 48774
2024-09-13 13:48:25,026:INFO:   Batch size = 128
2024-09-13 13:48:25,026:INFO:   Num steps = 1905
2024-09-13 13:49:27,595:INFO: Epoch: 1/5, Step: 50/381, Lr: 0.000000026-0.000026247, Loss: 1.194055, Time/step: 1.250175
2024-09-13 13:50:16,206:INFO: Epoch: 1/5, Step: 100/381, Lr: 0.000000052-0.000052493, Loss: 0.898039, Time/step: 0.972210
2024-09-13 13:51:05,207:INFO: Epoch: 1/5, Step: 150/381, Lr: 0.000000079-0.000078740, Loss: 0.795905, Time/step: 0.980014
2024-09-13 13:51:54,231:INFO: Epoch: 1/5, Step: 200/381, Lr: 0.000000097-0.000097305, Loss: 0.755921, Time/step: 0.980464
2024-09-13 13:52:43,651:INFO: Epoch: 1/5, Step: 250/381, Lr: 0.000000096-0.000095810, Loss: 0.459234, Time/step: 0.988390
2024-09-13 13:53:32,226:INFO: Epoch: 1/5, Step: 300/381, Lr: 0.000000094-0.000094005, Loss: 0.561311, Time/step: 0.971497
2024-09-13 13:54:21,831:INFO: Epoch: 1/5, Step: 350/381, Lr: 0.000000092-0.000091900, Loss: 0.580929, Time/step: 0.992104
2024-09-13 13:54:50,718:INFO: Epoch 1/5 Finished, Train Loss: 0.878348
2024-09-13 13:54:56,695:INFO: Model saved to logs/msvd/seqTransf_vit32/pytorch_model.bin.0
2024-09-13 13:54:56,697:INFO: Optimizer saved to logs/msvd/seqTransf_vit32/pytorch_opt.bin.0
2024-09-13 13:54:56,710:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-13 13:54:56,710:WARNING: sentence num: 27763, video num: 670
