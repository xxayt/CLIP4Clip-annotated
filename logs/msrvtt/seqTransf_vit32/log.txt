2024-09-11 10:33:57,173:INFO: device: cuda:2 n_gpu: 4
2024-09-11 10:33:57,177:INFO: device: cuda:3 n_gpu: 4
2024-09-11 10:33:57,177:INFO: Effective parameters:
2024-09-11 10:33:57,177:INFO:   <<< batch_size: 128
2024-09-11 10:33:57,177:INFO:   <<< batch_size_val: 16
2024-09-11 10:33:57,177:INFO:   <<< cache_dir: 
2024-09-11 10:33:57,177:INFO:   <<< coef_lr: 0.001
2024-09-11 10:33:57,177:INFO:   <<< cross_model: cross-base
2024-09-11 10:33:57,178:INFO:   <<< cross_num_hidden_layers: 4
2024-09-11 10:33:57,178:INFO:   <<< data_path: /home/xinzijie/Projects/CLIP4Clip/datasets/msrvtt_data/MSRVTT_data.json
2024-09-11 10:33:57,178:INFO:   <<< datatype: msrvtt
2024-09-11 10:33:57,178:INFO:   <<< do_eval: False
2024-09-11 10:33:57,178:INFO:   <<< do_lower_case: False
2024-09-11 10:33:57,178:INFO:   <<< do_pretrain: False
2024-09-11 10:33:57,178:INFO: device: cuda:1 n_gpu: 4
2024-09-11 10:33:57,178:INFO:   <<< do_train: True
2024-09-11 10:33:57,178:INFO:   <<< epochs: 5
2024-09-11 10:33:57,178:INFO:   <<< eval_frame_order: 0
2024-09-11 10:33:57,178:INFO:   <<< expand_msrvtt_sentences: True
2024-09-11 10:33:57,178:INFO:   <<< feature_framerate: 1
2024-09-11 10:33:57,179:INFO:   <<< features_path: /home/xinzijie/VisualSearch/msrvtt10k/ImageData
2024-09-11 10:33:57,179:INFO:   <<< fp16: False
2024-09-11 10:33:57,179:INFO:   <<< fp16_opt_level: O1
2024-09-11 10:33:57,179:INFO:   <<< freeze_layer_num: 0
2024-09-11 10:33:57,179:INFO:   <<< gradient_accumulation_steps: 1
2024-09-11 10:33:57,179:INFO:   <<< hard_negative_rate: 0.5
2024-09-11 10:33:57,179:INFO:   <<< init_model: None
2024-09-11 10:33:57,179:INFO:   <<< linear_patch: 2d
2024-09-11 10:33:57,179:INFO:   <<< local_rank: 0
2024-09-11 10:33:57,179:INFO:   <<< loose_type: True
2024-09-11 10:33:57,179:INFO:   <<< lr: 0.0001
2024-09-11 10:33:57,180:INFO:   <<< lr_decay: 0.9
2024-09-11 10:33:57,180:INFO:   <<< margin: 0.1
2024-09-11 10:33:57,180:INFO:   <<< max_frames: 12
2024-09-11 10:33:57,180:INFO:   <<< max_words: 32
2024-09-11 10:33:57,180:INFO:   <<< n_display: 50
2024-09-11 10:33:57,180:INFO:   <<< n_gpu: 1
2024-09-11 10:33:57,180:INFO:   <<< n_pair: 1
2024-09-11 10:33:57,180:INFO:   <<< name: seqTransf_vit32
2024-09-11 10:33:57,180:INFO:   <<< negative_weighting: 1
2024-09-11 10:33:57,180:INFO:   <<< num_thread_reader: 8
2024-09-11 10:33:57,180:INFO:   <<< output_dir: logs
2024-09-11 10:33:57,180:INFO:   <<< path_log: logs/msrvtt/seqTransf_vit32
2024-09-11 10:33:57,181:INFO:   <<< pretrained_clip_name: ViT-B/32
2024-09-11 10:33:57,181:INFO:   <<< rank: 0
2024-09-11 10:33:57,181:INFO:   <<< resume_model: None
2024-09-11 10:33:57,181:INFO:   <<< sampled_use_mil: False
2024-09-11 10:33:57,181:INFO:   <<< seed: 42
2024-09-11 10:33:57,181:INFO:   <<< sim_header: seqTransf
2024-09-11 10:33:57,181:INFO:   <<< slice_framepos: 2
2024-09-11 10:33:57,181:INFO:   <<< task_type: retrieval
2024-09-11 10:33:57,181:INFO:   <<< text_num_hidden_layers: 12
2024-09-11 10:33:57,181:INFO:   <<< train_csv: /home/xinzijie/Projects/CLIP4Clip/datasets/msrvtt_data/MSRVTT_train.9k.csv
2024-09-11 10:33:57,181:INFO:   <<< train_frame_order: 0
2024-09-11 10:33:57,181:INFO:   <<< use_mil: False
2024-09-11 10:33:57,181:INFO:   <<< val_csv: /home/xinzijie/Projects/CLIP4Clip/datasets/msrvtt_data/MSRVTT_JSFUSION_test.csv
2024-09-11 10:33:57,181:INFO:   <<< video_dim: 1024
2024-09-11 10:33:57,181:INFO:   <<< visual_num_hidden_layers: 12
2024-09-11 10:33:57,181:INFO:   <<< warmup_proportion: 0.1
2024-09-11 10:33:57,182:INFO:   <<< world_size: 4
2024-09-11 10:33:57,182:INFO: device: cuda:0 n_gpu: 4
2024-09-11 10:33:59,563:INFO: loading archive file /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base
2024-09-11 10:33:59,564:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-09-11 10:33:59,564:INFO: Weight doesn't exsits. /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base/cross_pytorch_model.bin
2024-09-11 10:33:59,564:WARNING: Stage-One:True, Stage-Two:False
2024-09-11 10:33:59,564:WARNING: Test retrieval by loose type.
2024-09-11 10:33:59,565:WARNING: 	 embed_dim: 512
2024-09-11 10:33:59,565:WARNING: 	 image_resolution: 224
2024-09-11 10:33:59,565:WARNING: 	 vision_layers: 12
2024-09-11 10:33:59,565:WARNING: 	 vision_width: 768
2024-09-11 10:33:59,565:WARNING: 	 vision_patch_size: 32
2024-09-11 10:33:59,565:WARNING: 	 context_length: 77
2024-09-11 10:33:59,565:WARNING: 	 vocab_size: 49408
2024-09-11 10:33:59,565:WARNING: 	 transformer_width: 512
2024-09-11 10:33:59,565:WARNING: 	 transformer_heads: 8
2024-09-11 10:33:59,565:WARNING: 	 transformer_layers: 12
2024-09-11 10:33:59,565:WARNING: 		 linear_patch: 2d
2024-09-11 10:33:59,565:WARNING: 	 cut_top_layer: 0
2024-09-11 10:34:01,442:WARNING: 	 sim_header: seqTransf
2024-09-11 10:34:06,399:INFO: --------------------
2024-09-11 10:34:06,400:INFO: Weights from pretrained model not used in CLIP4Clip: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2024-09-11 10:35:33,259:INFO: device: cuda:2 n_gpu: 4
2024-09-11 10:35:33,279:INFO: device: cuda:3 n_gpu: 4
2024-09-11 10:35:33,283:INFO: device: cuda:1 n_gpu: 4
2024-09-11 10:35:33,284:INFO: Effective parameters:
2024-09-11 10:35:33,285:INFO:   <<< batch_size: 128
2024-09-11 10:35:33,285:INFO:   <<< batch_size_val: 16
2024-09-11 10:35:33,285:INFO:   <<< cache_dir: 
2024-09-11 10:35:33,285:INFO:   <<< coef_lr: 0.001
2024-09-11 10:35:33,285:INFO:   <<< cross_model: cross-base
2024-09-11 10:35:33,285:INFO:   <<< cross_num_hidden_layers: 4
2024-09-11 10:35:33,285:INFO:   <<< data_path: /home/xinzijie/Projects/CLIP4Clip-annotated/datasets/msrvtt_data/MSRVTT_data.json
2024-09-11 10:35:33,285:INFO:   <<< datatype: msrvtt
2024-09-11 10:35:33,285:INFO:   <<< do_eval: False
2024-09-11 10:35:33,285:INFO:   <<< do_lower_case: False
2024-09-11 10:35:33,285:INFO:   <<< do_pretrain: False
2024-09-11 10:35:33,285:INFO:   <<< do_train: True
2024-09-11 10:35:33,285:INFO:   <<< epochs: 5
2024-09-11 10:35:33,285:INFO:   <<< eval_frame_order: 0
2024-09-11 10:35:33,285:INFO:   <<< expand_msrvtt_sentences: True
2024-09-11 10:35:33,285:INFO:   <<< feature_framerate: 1
2024-09-11 10:35:33,285:INFO:   <<< features_path: /home/xinzijie/VisualSearch/msrvtt10k/ImageData
2024-09-11 10:35:33,285:INFO:   <<< fp16: False
2024-09-11 10:35:33,285:INFO:   <<< fp16_opt_level: O1
2024-09-11 10:35:33,286:INFO:   <<< freeze_layer_num: 0
2024-09-11 10:35:33,286:INFO:   <<< gradient_accumulation_steps: 1
2024-09-11 10:35:33,286:INFO:   <<< hard_negative_rate: 0.5
2024-09-11 10:35:33,286:INFO:   <<< init_model: None
2024-09-11 10:35:33,286:INFO:   <<< linear_patch: 2d
2024-09-11 10:35:33,286:INFO:   <<< local_rank: 0
2024-09-11 10:35:33,286:INFO:   <<< loose_type: True
2024-09-11 10:35:33,286:INFO:   <<< lr: 0.0001
2024-09-11 10:35:33,286:INFO:   <<< lr_decay: 0.9
2024-09-11 10:35:33,286:INFO:   <<< margin: 0.1
2024-09-11 10:35:33,286:INFO:   <<< max_frames: 12
2024-09-11 10:35:33,286:INFO:   <<< max_words: 32
2024-09-11 10:35:33,286:INFO:   <<< n_display: 50
2024-09-11 10:35:33,286:INFO:   <<< n_gpu: 1
2024-09-11 10:35:33,286:INFO:   <<< n_pair: 1
2024-09-11 10:35:33,287:INFO:   <<< name: seqTransf_vit32
2024-09-11 10:35:33,287:INFO:   <<< negative_weighting: 1
2024-09-11 10:35:33,287:INFO:   <<< num_thread_reader: 8
2024-09-11 10:35:33,287:INFO:   <<< output_dir: logs
2024-09-11 10:35:33,287:INFO:   <<< path_log: logs/msrvtt/seqTransf_vit32
2024-09-11 10:35:33,287:INFO:   <<< pretrained_clip_name: ViT-B/32
2024-09-11 10:35:33,287:INFO:   <<< rank: 0
2024-09-11 10:35:33,287:INFO:   <<< resume_model: None
2024-09-11 10:35:33,287:INFO:   <<< sampled_use_mil: False
2024-09-11 10:35:33,287:INFO:   <<< seed: 42
2024-09-11 10:35:33,287:INFO:   <<< sim_header: seqTransf
2024-09-11 10:35:33,287:INFO:   <<< slice_framepos: 2
2024-09-11 10:35:33,287:INFO:   <<< task_type: retrieval
2024-09-11 10:35:33,287:INFO:   <<< text_num_hidden_layers: 12
2024-09-11 10:35:33,287:INFO:   <<< train_csv: /home/xinzijie/Projects/CLIP4Clip-annotated/datasets/msrvtt_data/MSRVTT_train.9k.csv
2024-09-11 10:35:33,288:INFO:   <<< train_frame_order: 0
2024-09-11 10:35:33,288:INFO:   <<< use_mil: False
2024-09-11 10:35:33,288:INFO:   <<< val_csv: /home/xinzijie/Projects/CLIP4Clip-annotated/datasets/msrvtt_data/MSRVTT_JSFUSION_test.csv
2024-09-11 10:35:33,288:INFO:   <<< video_dim: 1024
2024-09-11 10:35:33,288:INFO:   <<< visual_num_hidden_layers: 12
2024-09-11 10:35:33,288:INFO:   <<< warmup_proportion: 0.1
2024-09-11 10:35:33,288:INFO:   <<< world_size: 4
2024-09-11 10:35:33,288:INFO: device: cuda:0 n_gpu: 4
2024-09-11 10:35:36,046:INFO: loading archive file /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base
2024-09-11 10:35:36,047:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-09-11 10:35:36,048:INFO: Weight doesn't exsits. /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base/cross_pytorch_model.bin
2024-09-11 10:35:36,048:WARNING: Stage-One:True, Stage-Two:False
2024-09-11 10:35:36,048:WARNING: Test retrieval by loose type.
2024-09-11 10:35:36,048:WARNING: 	 embed_dim: 512
2024-09-11 10:35:36,049:WARNING: 	 image_resolution: 224
2024-09-11 10:35:36,049:WARNING: 	 vision_layers: 12
2024-09-11 10:35:36,049:WARNING: 	 vision_width: 768
2024-09-11 10:35:36,049:WARNING: 	 vision_patch_size: 32
2024-09-11 10:35:36,049:WARNING: 	 context_length: 77
2024-09-11 10:35:36,049:WARNING: 	 vocab_size: 49408
2024-09-11 10:35:36,049:WARNING: 	 transformer_width: 512
2024-09-11 10:35:36,049:WARNING: 	 transformer_heads: 8
2024-09-11 10:35:36,049:WARNING: 	 transformer_layers: 12
2024-09-11 10:35:36,049:WARNING: 		 linear_patch: 2d
2024-09-11 10:35:36,049:WARNING: 	 cut_top_layer: 0
2024-09-11 10:35:38,232:WARNING: 	 sim_header: seqTransf
2024-09-11 10:35:43,801:INFO: --------------------
2024-09-11 10:35:43,801:INFO: Weights from pretrained model not used in CLIP4Clip: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2024-09-11 10:35:46,308:INFO: ***** Running test *****
2024-09-11 10:35:46,308:INFO:   Num examples = 1000
2024-09-11 10:35:46,308:INFO:   Batch size = 16
2024-09-11 10:35:46,308:INFO:   Num steps = 63
2024-09-11 10:35:46,308:INFO: ***** Running val *****
2024-09-11 10:35:46,308:INFO:   Num examples = 1000
2024-09-11 10:36:07,537:INFO: device: cuda:1 n_gpu: 4
2024-09-11 10:36:07,538:INFO: Effective parameters:
2024-09-11 10:36:07,538:INFO:   <<< batch_size: 128
2024-09-11 10:36:07,538:INFO:   <<< batch_size_val: 16
2024-09-11 10:36:07,538:INFO:   <<< cache_dir: 
2024-09-11 10:36:07,538:INFO:   <<< coef_lr: 0.001
2024-09-11 10:36:07,538:INFO:   <<< cross_model: cross-base
2024-09-11 10:36:07,538:INFO:   <<< cross_num_hidden_layers: 4
2024-09-11 10:36:07,538:INFO:   <<< data_path: ./datasets/msrvtt_data/MSRVTT_data.json
2024-09-11 10:36:07,538:INFO:   <<< datatype: msrvtt
2024-09-11 10:36:07,539:INFO:   <<< do_eval: False
2024-09-11 10:36:07,539:INFO:   <<< do_lower_case: False
2024-09-11 10:36:07,539:INFO:   <<< do_pretrain: False
2024-09-11 10:36:07,539:INFO:   <<< do_train: True
2024-09-11 10:36:07,539:INFO:   <<< epochs: 5
2024-09-11 10:36:07,539:INFO:   <<< eval_frame_order: 0
2024-09-11 10:36:07,539:INFO:   <<< expand_msrvtt_sentences: True
2024-09-11 10:36:07,539:INFO:   <<< feature_framerate: 1
2024-09-11 10:36:07,539:INFO:   <<< features_path: /home/xinzijie/VisualSearch/msrvtt10k/ImageData
2024-09-11 10:36:07,539:INFO:   <<< fp16: False
2024-09-11 10:36:07,539:INFO:   <<< fp16_opt_level: O1
2024-09-11 10:36:07,539:INFO:   <<< freeze_layer_num: 0
2024-09-11 10:36:07,539:INFO:   <<< gradient_accumulation_steps: 1
2024-09-11 10:36:07,539:INFO:   <<< hard_negative_rate: 0.5
2024-09-11 10:36:07,539:INFO:   <<< init_model: None
2024-09-11 10:36:07,540:INFO:   <<< linear_patch: 2d
2024-09-11 10:36:07,540:INFO:   <<< local_rank: 0
2024-09-11 10:36:07,540:INFO:   <<< loose_type: True
2024-09-11 10:36:07,540:INFO:   <<< lr: 0.0001
2024-09-11 10:36:07,540:INFO:   <<< lr_decay: 0.9
2024-09-11 10:36:07,540:INFO:   <<< margin: 0.1
2024-09-11 10:36:07,540:INFO:   <<< max_frames: 12
2024-09-11 10:36:07,540:INFO:   <<< max_words: 32
2024-09-11 10:36:07,540:INFO:   <<< n_display: 50
2024-09-11 10:36:07,540:INFO:   <<< n_gpu: 1
2024-09-11 10:36:07,540:INFO:   <<< n_pair: 1
2024-09-11 10:36:07,540:INFO:   <<< name: seqTransf_vit32
2024-09-11 10:36:07,540:INFO:   <<< negative_weighting: 1
2024-09-11 10:36:07,541:INFO:   <<< num_thread_reader: 8
2024-09-11 10:36:07,541:INFO:   <<< output_dir: logs
2024-09-11 10:36:07,541:INFO:   <<< path_log: logs/msrvtt/seqTransf_vit32
2024-09-11 10:36:07,541:INFO:   <<< pretrained_clip_name: ViT-B/32
2024-09-11 10:36:07,541:INFO:   <<< rank: 0
2024-09-11 10:36:07,541:INFO: device: cuda:3 n_gpu: 4
2024-09-11 10:36:07,541:INFO:   <<< resume_model: None
2024-09-11 10:36:07,541:INFO:   <<< sampled_use_mil: False
2024-09-11 10:36:07,541:INFO:   <<< seed: 42
2024-09-11 10:36:07,541:INFO:   <<< sim_header: seqTransf
2024-09-11 10:36:07,541:INFO:   <<< slice_framepos: 2
2024-09-11 10:36:07,541:INFO:   <<< task_type: retrieval
2024-09-11 10:36:07,541:INFO:   <<< text_num_hidden_layers: 12
2024-09-11 10:36:07,541:INFO: device: cuda:2 n_gpu: 4
2024-09-11 10:36:07,541:INFO:   <<< train_csv: ./datasets/msrvtt_data/MSRVTT_train.9k.csv
2024-09-11 10:36:07,541:INFO:   <<< train_frame_order: 0
2024-09-11 10:36:07,541:INFO:   <<< use_mil: False
2024-09-11 10:36:07,541:INFO:   <<< val_csv: ./datasets/msrvtt_data/MSRVTT_JSFUSION_test.csv
2024-09-11 10:36:07,542:INFO:   <<< video_dim: 1024
2024-09-11 10:36:07,542:INFO:   <<< visual_num_hidden_layers: 12
2024-09-11 10:36:07,542:INFO:   <<< warmup_proportion: 0.1
2024-09-11 10:36:07,542:INFO:   <<< world_size: 4
2024-09-11 10:36:07,542:INFO: device: cuda:0 n_gpu: 4
2024-09-11 10:36:09,905:INFO: loading archive file /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base
2024-09-11 10:36:09,906:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-09-11 10:36:09,906:INFO: Weight doesn't exsits. /data3/xinzijie/Projects/CLIP4Clip-annotated/modules/cross-base/cross_pytorch_model.bin
2024-09-11 10:36:09,906:WARNING: Stage-One:True, Stage-Two:False
2024-09-11 10:36:09,906:WARNING: Test retrieval by loose type.
2024-09-11 10:36:09,907:WARNING: 	 embed_dim: 512
2024-09-11 10:36:09,907:WARNING: 	 image_resolution: 224
2024-09-11 10:36:09,907:WARNING: 	 vision_layers: 12
2024-09-11 10:36:09,907:WARNING: 	 vision_width: 768
2024-09-11 10:36:09,907:WARNING: 	 vision_patch_size: 32
2024-09-11 10:36:09,907:WARNING: 	 context_length: 77
2024-09-11 10:36:09,907:WARNING: 	 vocab_size: 49408
2024-09-11 10:36:09,907:WARNING: 	 transformer_width: 512
2024-09-11 10:36:09,907:WARNING: 	 transformer_heads: 8
2024-09-11 10:36:09,907:WARNING: 	 transformer_layers: 12
2024-09-11 10:36:09,907:WARNING: 		 linear_patch: 2d
2024-09-11 10:36:09,907:WARNING: 	 cut_top_layer: 0
2024-09-11 10:36:11,773:WARNING: 	 sim_header: seqTransf
2024-09-11 10:36:16,642:INFO: --------------------
2024-09-11 10:36:16,642:INFO: Weights from pretrained model not used in CLIP4Clip: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2024-09-11 10:36:18,875:INFO: ***** Running test *****
2024-09-11 10:36:18,875:INFO:   Num examples = 1000
2024-09-11 10:36:18,875:INFO:   Batch size = 16
2024-09-11 10:36:18,875:INFO:   Num steps = 63
2024-09-11 10:36:18,875:INFO: ***** Running val *****
2024-09-11 10:36:18,875:INFO:   Num examples = 1000
2024-09-11 10:36:45,932:INFO: ***** Running training *****
2024-09-11 10:36:45,932:INFO:   Num examples = 180000
2024-09-11 10:36:45,932:INFO:   Batch size = 128
2024-09-11 10:36:45,932:INFO:   Num steps = 7030
2024-09-11 10:39:52,856:INFO: Epoch: 1/5, Step: 50/1406, Lr: 0.000000007-0.000007112, Loss: 1.650206, Time/step: 3.737247
2024-09-11 10:41:33,271:INFO: Epoch: 1/5, Step: 100/1406, Lr: 0.000000014-0.000014225, Loss: 1.702710, Time/step: 2.008301
2024-09-11 10:42:36,052:INFO: Epoch: 1/5, Step: 150/1406, Lr: 0.000000021-0.000021337, Loss: 1.060592, Time/step: 1.255589
2024-09-11 10:43:36,005:INFO: Epoch: 1/5, Step: 200/1406, Lr: 0.000000028-0.000028450, Loss: 1.295946, Time/step: 1.199021
2024-09-11 10:44:35,006:INFO: Epoch: 1/5, Step: 250/1406, Lr: 0.000000036-0.000035562, Loss: 1.184925, Time/step: 1.179981
2024-09-11 10:45:32,134:INFO: Epoch: 1/5, Step: 300/1406, Lr: 0.000000043-0.000042674, Loss: 1.193660, Time/step: 1.142538
2024-09-11 10:46:44,098:INFO: Epoch: 1/5, Step: 350/1406, Lr: 0.000000050-0.000049787, Loss: 1.152657, Time/step: 1.439276
2024-09-11 10:47:41,604:INFO: Epoch: 1/5, Step: 400/1406, Lr: 0.000000057-0.000056899, Loss: 1.135045, Time/step: 1.150099
2024-09-11 10:48:41,294:INFO: Epoch: 1/5, Step: 450/1406, Lr: 0.000000064-0.000064011, Loss: 0.904991, Time/step: 1.193781
2024-09-11 10:49:39,823:INFO: Epoch: 1/5, Step: 500/1406, Lr: 0.000000071-0.000071124, Loss: 1.000421, Time/step: 1.170562
2024-09-11 10:50:37,425:INFO: Epoch: 1/5, Step: 550/1406, Lr: 0.000000078-0.000078236, Loss: 0.866489, Time/step: 1.152023
2024-09-11 10:51:38,087:INFO: Epoch: 1/5, Step: 600/1406, Lr: 0.000000085-0.000085349, Loss: 1.050133, Time/step: 1.213219
2024-09-11 10:52:37,579:INFO: Epoch: 1/5, Step: 650/1406, Lr: 0.000000092-0.000092461, Loss: 1.045832, Time/step: 1.189827
2024-09-11 10:53:40,861:INFO: Epoch: 1/5, Step: 700/1406, Lr: 0.000000100-0.000099573, Loss: 0.978971, Time/step: 1.265616
2024-09-11 10:55:05,052:INFO: Epoch: 1/5, Step: 750/1406, Lr: 0.000000097-0.000097218, Loss: 0.795441, Time/step: 1.683806
2024-09-11 10:56:22,496:INFO: Epoch: 1/5, Step: 800/1406, Lr: 0.000000097-0.000096839, Loss: 0.871938, Time/step: 1.548867
2024-09-11 10:57:48,590:INFO: Epoch: 1/5, Step: 850/1406, Lr: 0.000000096-0.000096436, Loss: 0.794940, Time/step: 1.721889
2024-09-11 10:58:51,264:INFO: Epoch: 1/5, Step: 900/1406, Lr: 0.000000096-0.000096010, Loss: 1.014917, Time/step: 1.253419
2024-09-11 10:59:49,526:INFO: Epoch: 1/5, Step: 950/1406, Lr: 0.000000096-0.000095561, Loss: 0.926026, Time/step: 1.165221
2024-09-11 11:00:51,073:INFO: Epoch: 1/5, Step: 1000/1406, Lr: 0.000000095-0.000095090, Loss: 0.983327, Time/step: 1.230913
2024-09-11 11:01:48,043:INFO: Epoch: 1/5, Step: 1050/1406, Lr: 0.000000095-0.000094596, Loss: 0.834840, Time/step: 1.139380
2024-09-11 11:02:48,890:INFO: Epoch: 1/5, Step: 1100/1406, Lr: 0.000000094-0.000094080, Loss: 0.633821, Time/step: 1.216923
2024-09-11 11:03:46,491:INFO: Epoch: 1/5, Step: 1150/1406, Lr: 0.000000094-0.000093541, Loss: 0.698933, Time/step: 1.151996
2024-09-11 11:04:44,970:INFO: Epoch: 1/5, Step: 1200/1406, Lr: 0.000000093-0.000092981, Loss: 0.820531, Time/step: 1.169563
2024-09-11 11:05:43,511:INFO: Epoch: 1/5, Step: 1250/1406, Lr: 0.000000092-0.000092400, Loss: 0.831262, Time/step: 1.170794
2024-09-11 11:06:43,493:INFO: Epoch: 1/5, Step: 1300/1406, Lr: 0.000000092-0.000091797, Loss: 0.663580, Time/step: 1.199623
2024-09-11 11:07:44,630:INFO: Epoch: 1/5, Step: 1350/1406, Lr: 0.000000091-0.000091174, Loss: 0.685722, Time/step: 1.222735
2024-09-11 11:08:41,381:INFO: Epoch: 1/5, Step: 1400/1406, Lr: 0.000000091-0.000090530, Loss: 0.431579, Time/step: 1.134969
2024-09-11 11:08:47,216:INFO: Epoch 1/5 Finished, Train Loss: 1.001546
2024-09-11 11:08:49,836:INFO: Model saved to logs/msrvtt/seqTransf_vit32/pytorch_model.bin.0
2024-09-11 11:08:49,837:INFO: Optimizer saved to logs/msrvtt/seqTransf_vit32/pytorch_opt.bin.0
2024-09-11 11:08:49,848:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-11 11:08:49,848:WARNING: sentence num: 1000, video num: 1000
2024-09-11 11:10:26,927:INFO: before reshape, sim matrix size: 1000 x 1000
2024-09-11 11:10:26,947:INFO: after reshape, sim matrix size: 1000 x 1 x 1000
2024-09-11 11:10:27,328:INFO: Text-to-Video:
2024-09-11 11:10:27,328:INFO: 	>>>  R@1: 41.3 - R@5: 71.1 - R@10: 80.1 - Median R: 2.0 - Mean R: 15.7
2024-09-11 11:10:27,328:INFO: Video-to-Text:
2024-09-11 11:10:27,328:INFO: 	>>>  V2T$R@1: 41.3 - V2T$R@5: 68.8 - V2T$R@10: 80.0 - V2T$Median R: 2.0 - V2T$Mean R: 12.8
2024-09-11 11:10:27,333:INFO: The best model is: logs/msrvtt/seqTransf_vit32/pytorch_model.bin.0, the R1 is: 41.3000
2024-09-11 11:11:32,866:INFO: Epoch: 2/5, Step: 44/1406, Lr: 0.000000090-0.000089865, Loss: 0.562195, Time/step: 1.306058
2024-09-11 11:12:35,781:INFO: Epoch: 2/5, Step: 94/1406, Lr: 0.000000089-0.000089181, Loss: 0.823340, Time/step: 1.258280
2024-09-11 11:13:35,312:INFO: Epoch: 2/5, Step: 144/1406, Lr: 0.000000088-0.000088477, Loss: 0.606624, Time/step: 1.190609
2024-09-11 11:14:35,781:INFO: Epoch: 2/5, Step: 194/1406, Lr: 0.000000088-0.000087754, Loss: 0.610177, Time/step: 1.209368
2024-09-11 11:15:35,533:INFO: Epoch: 2/5, Step: 244/1406, Lr: 0.000000087-0.000087012, Loss: 0.467520, Time/step: 1.195016
2024-09-11 11:16:35,588:INFO: Epoch: 2/5, Step: 294/1406, Lr: 0.000000086-0.000086252, Loss: 0.575769, Time/step: 1.201096
2024-09-11 11:17:34,435:INFO: Epoch: 2/5, Step: 344/1406, Lr: 0.000000085-0.000085474, Loss: 0.836600, Time/step: 1.176916
2024-09-11 11:18:34,110:INFO: Epoch: 2/5, Step: 394/1406, Lr: 0.000000085-0.000084678, Loss: 0.700875, Time/step: 1.193480
2024-09-11 11:19:34,476:INFO: Epoch: 2/5, Step: 444/1406, Lr: 0.000000084-0.000083864, Loss: 0.654350, Time/step: 1.207301
2024-09-11 11:20:33,138:INFO: Epoch: 2/5, Step: 494/1406, Lr: 0.000000083-0.000083034, Loss: 0.680661, Time/step: 1.173232
2024-09-11 11:21:33,490:INFO: Epoch: 2/5, Step: 544/1406, Lr: 0.000000082-0.000082187, Loss: 0.499030, Time/step: 1.207029
2024-09-11 11:22:33,978:INFO: Epoch: 2/5, Step: 594/1406, Lr: 0.000000081-0.000081324, Loss: 0.649853, Time/step: 1.209732
2024-09-11 11:23:32,624:INFO: Epoch: 2/5, Step: 644/1406, Lr: 0.000000080-0.000080445, Loss: 0.592783, Time/step: 1.172918
2024-09-11 11:24:32,033:INFO: Epoch: 2/5, Step: 694/1406, Lr: 0.000000080-0.000079552, Loss: 0.677929, Time/step: 1.188168
2024-09-11 11:25:30,201:INFO: Epoch: 2/5, Step: 744/1406, Lr: 0.000000079-0.000078643, Loss: 0.657452, Time/step: 1.163337
2024-09-11 11:26:30,435:INFO: Epoch: 2/5, Step: 794/1406, Lr: 0.000000078-0.000077720, Loss: 0.520967, Time/step: 1.204664
2024-09-11 11:27:30,005:INFO: Epoch: 2/5, Step: 844/1406, Lr: 0.000000077-0.000076784, Loss: 0.604246, Time/step: 1.191378
2024-09-11 11:28:29,136:INFO: Epoch: 2/5, Step: 894/1406, Lr: 0.000000076-0.000075834, Loss: 0.585246, Time/step: 1.182602
2024-09-11 11:29:28,385:INFO: Epoch: 2/5, Step: 944/1406, Lr: 0.000000075-0.000074871, Loss: 0.694945, Time/step: 1.184984
2024-09-11 11:30:29,167:INFO: Epoch: 2/5, Step: 994/1406, Lr: 0.000000074-0.000073896, Loss: 0.601574, Time/step: 1.215620
2024-09-11 11:31:27,306:INFO: Epoch: 2/5, Step: 1044/1406, Lr: 0.000000073-0.000072908, Loss: 0.596879, Time/step: 1.162760
2024-09-11 11:32:26,206:INFO: Epoch: 2/5, Step: 1094/1406, Lr: 0.000000072-0.000071910, Loss: 0.623889, Time/step: 1.177977
2024-09-11 11:33:26,642:INFO: Epoch: 2/5, Step: 1144/1406, Lr: 0.000000071-0.000070900, Loss: 0.563972, Time/step: 1.208724
2024-09-11 11:34:25,081:INFO: Epoch: 2/5, Step: 1194/1406, Lr: 0.000000070-0.000069880, Loss: 0.802532, Time/step: 1.168757
2024-09-11 11:35:24,890:INFO: Epoch: 2/5, Step: 1244/1406, Lr: 0.000000069-0.000068850, Loss: 0.465654, Time/step: 1.196155
2024-09-11 11:36:23,863:INFO: Epoch: 2/5, Step: 1294/1406, Lr: 0.000000068-0.000067811, Loss: 0.726845, Time/step: 1.179459
2024-09-11 11:37:23,421:INFO: Epoch: 2/5, Step: 1344/1406, Lr: 0.000000067-0.000066762, Loss: 0.654712, Time/step: 1.191133
2024-09-11 11:38:21,876:INFO: Epoch: 2/5, Step: 1394/1406, Lr: 0.000000066-0.000065706, Loss: 0.564871, Time/step: 1.169085
2024-09-11 11:38:33,855:INFO: Epoch 2/5 Finished, Train Loss: 0.588579
2024-09-11 11:38:36,483:INFO: Model saved to logs/msrvtt/seqTransf_vit32/pytorch_model.bin.1
2024-09-11 11:38:36,484:INFO: Optimizer saved to logs/msrvtt/seqTransf_vit32/pytorch_opt.bin.1
2024-09-11 11:38:36,494:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-11 11:38:36,495:WARNING: sentence num: 1000, video num: 1000
2024-09-11 11:39:40,705:INFO: before reshape, sim matrix size: 1000 x 1000
2024-09-11 11:39:40,724:INFO: after reshape, sim matrix size: 1000 x 1 x 1000
2024-09-11 11:39:41,028:INFO: Text-to-Video:
2024-09-11 11:39:41,028:INFO: 	>>>  R@1: 43.0 - R@5: 70.2 - R@10: 81.4 - Median R: 2.0 - Mean R: 15.0
2024-09-11 11:39:41,028:INFO: Video-to-Text:
2024-09-11 11:39:41,028:INFO: 	>>>  V2T$R@1: 42.3 - V2T$R@5: 69.6 - V2T$R@10: 81.8 - V2T$Median R: 2.0 - V2T$Mean R: 11.8
2024-09-11 11:39:41,031:INFO: The best model is: logs/msrvtt/seqTransf_vit32/pytorch_model.bin.1, the R1 is: 43.0000
2024-09-11 11:40:33,614:INFO: Epoch: 3/5, Step: 38/1406, Lr: 0.000000065-0.000064641, Loss: 0.362624, Time/step: 1.047088
2024-09-11 11:41:33,983:INFO: Epoch: 3/5, Step: 88/1406, Lr: 0.000000064-0.000063569, Loss: 0.434617, Time/step: 1.207343
2024-09-11 11:42:34,282:INFO: Epoch: 3/5, Step: 138/1406, Lr: 0.000000062-0.000062491, Loss: 0.274095, Time/step: 1.205965
2024-09-11 11:43:32,451:INFO: Epoch: 3/5, Step: 188/1406, Lr: 0.000000061-0.000061406, Loss: 0.315484, Time/step: 1.163362
2024-09-11 11:44:31,612:INFO: Epoch: 3/5, Step: 238/1406, Lr: 0.000000060-0.000060315, Loss: 0.477999, Time/step: 1.183204
2024-09-11 11:45:31,716:INFO: Epoch: 3/5, Step: 288/1406, Lr: 0.000000059-0.000059220, Loss: 0.385798, Time/step: 1.202046
2024-09-11 11:46:31,298:INFO: Epoch: 3/5, Step: 338/1406, Lr: 0.000000058-0.000058120, Loss: 0.218501, Time/step: 1.191629
2024-09-11 11:47:30,132:INFO: Epoch: 3/5, Step: 388/1406, Lr: 0.000000057-0.000057015, Loss: 0.279557, Time/step: 1.176652
2024-09-11 11:48:28,425:INFO: Epoch: 3/5, Step: 438/1406, Lr: 0.000000056-0.000055907, Loss: 0.501500, Time/step: 1.165838
2024-09-11 11:49:26,916:INFO: Epoch: 3/5, Step: 488/1406, Lr: 0.000000055-0.000054797, Loss: 0.293910, Time/step: 1.169810
2024-09-11 11:50:28,666:INFO: Epoch: 3/5, Step: 538/1406, Lr: 0.000000054-0.000053683, Loss: 0.336343, Time/step: 1.234993
2024-09-11 11:51:27,152:INFO: Epoch: 3/5, Step: 588/1406, Lr: 0.000000053-0.000052568, Loss: 0.352495, Time/step: 1.169699
2024-09-11 11:52:25,398:INFO: Epoch: 3/5, Step: 638/1406, Lr: 0.000000051-0.000051452, Loss: 0.345602, Time/step: 1.164875
2024-09-11 11:53:24,779:INFO: Epoch: 3/5, Step: 688/1406, Lr: 0.000000050-0.000050335, Loss: 0.445678, Time/step: 1.187613
2024-09-11 11:54:25,142:INFO: Epoch: 3/5, Step: 738/1406, Lr: 0.000000049-0.000049218, Loss: 0.302926, Time/step: 1.207247
2024-09-11 11:55:23,535:INFO: Epoch: 3/5, Step: 788/1406, Lr: 0.000000048-0.000048101, Loss: 0.432297, Time/step: 1.167824
2024-09-11 11:56:21,372:INFO: Epoch: 3/5, Step: 838/1406, Lr: 0.000000047-0.000046985, Loss: 0.425293, Time/step: 1.156730
2024-09-11 11:57:19,969:INFO: Epoch: 3/5, Step: 888/1406, Lr: 0.000000046-0.000045871, Loss: 0.279186, Time/step: 1.171911
2024-09-11 11:58:18,875:INFO: Epoch: 3/5, Step: 938/1406, Lr: 0.000000045-0.000044759, Loss: 0.538512, Time/step: 1.178090
2024-09-11 11:59:17,688:INFO: Epoch: 3/5, Step: 988/1406, Lr: 0.000000044-0.000043649, Loss: 0.293588, Time/step: 1.176242
2024-09-11 12:00:16,881:INFO: Epoch: 3/5, Step: 1038/1406, Lr: 0.000000043-0.000042543, Loss: 0.412643, Time/step: 1.183860
2024-09-11 12:01:14,886:INFO: Epoch: 3/5, Step: 1088/1406, Lr: 0.000000041-0.000041440, Loss: 0.403518, Time/step: 1.160084
2024-09-11 12:02:13,287:INFO: Epoch: 3/5, Step: 1138/1406, Lr: 0.000000040-0.000040341, Loss: 0.325380, Time/step: 1.167993
2024-09-11 12:03:12,517:INFO: Epoch: 3/5, Step: 1188/1406, Lr: 0.000000039-0.000039248, Loss: 0.389565, Time/step: 1.184600
2024-09-11 12:04:10,558:INFO: Epoch: 3/5, Step: 1238/1406, Lr: 0.000000038-0.000038159, Loss: 0.328125, Time/step: 1.160796
2024-09-11 12:05:11,170:INFO: Epoch: 3/5, Step: 1288/1406, Lr: 0.000000037-0.000037077, Loss: 0.356111, Time/step: 1.212216
2024-09-11 12:06:13,636:INFO: Epoch: 3/5, Step: 1338/1406, Lr: 0.000000036-0.000036001, Loss: 0.408199, Time/step: 1.249296
2024-09-11 12:07:13,459:INFO: Epoch: 3/5, Step: 1388/1406, Lr: 0.000000035-0.000034932, Loss: 0.233986, Time/step: 1.196447
2024-09-11 12:07:31,435:INFO: Epoch 3/5 Finished, Train Loss: 0.393782
2024-09-11 12:07:34,385:INFO: Model saved to logs/msrvtt/seqTransf_vit32/pytorch_model.bin.2
2024-09-11 12:07:34,385:INFO: Optimizer saved to logs/msrvtt/seqTransf_vit32/pytorch_opt.bin.2
2024-09-11 12:07:34,395:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-11 12:07:34,395:WARNING: sentence num: 1000, video num: 1000
2024-09-11 12:08:29,761:INFO: before reshape, sim matrix size: 1000 x 1000
2024-09-11 12:08:29,780:INFO: after reshape, sim matrix size: 1000 x 1 x 1000
2024-09-11 12:08:30,051:INFO: Text-to-Video:
2024-09-11 12:08:30,052:INFO: 	>>>  R@1: 42.8 - R@5: 70.8 - R@10: 81.2 - Median R: 2.0 - Mean R: 14.8
2024-09-11 12:08:30,052:INFO: Video-to-Text:
2024-09-11 12:08:30,052:INFO: 	>>>  V2T$R@1: 41.5 - V2T$R@5: 70.2 - V2T$R@10: 81.3 - V2T$Median R: 2.0 - V2T$Mean R: 11.4
2024-09-11 12:08:30,054:INFO: The best model is: logs/msrvtt/seqTransf_vit32/pytorch_model.bin.1, the R1 is: 43.0000
2024-09-11 12:09:15,189:INFO: Epoch: 4/5, Step: 32/1406, Lr: 0.000000034-0.000033871, Loss: 0.335101, Time/step: 0.898167
2024-09-11 12:10:13,256:INFO: Epoch: 4/5, Step: 82/1406, Lr: 0.000000033-0.000032817, Loss: 0.312974, Time/step: 1.161300
2024-09-11 12:11:10,941:INFO: Epoch: 4/5, Step: 132/1406, Lr: 0.000000032-0.000031773, Loss: 0.245111, Time/step: 1.153687
2024-09-11 12:12:08,734:INFO: Epoch: 4/5, Step: 182/1406, Lr: 0.000000031-0.000030737, Loss: 0.307001, Time/step: 1.155849
2024-09-11 12:13:06,859:INFO: Epoch: 4/5, Step: 232/1406, Lr: 0.000000030-0.000029711, Loss: 0.274382, Time/step: 1.162483
2024-09-11 12:14:06,278:INFO: Epoch: 4/5, Step: 282/1406, Lr: 0.000000029-0.000028695, Loss: 0.225610, Time/step: 1.188337
2024-09-11 12:15:02,785:INFO: Epoch: 4/5, Step: 332/1406, Lr: 0.000000028-0.000027690, Loss: 0.209895, Time/step: 1.130134
2024-09-11 12:16:00,159:INFO: Epoch: 4/5, Step: 382/1406, Lr: 0.000000027-0.000026695, Loss: 0.481013, Time/step: 1.147446
2024-09-11 12:16:59,023:INFO: Epoch: 4/5, Step: 432/1406, Lr: 0.000000026-0.000025713, Loss: 0.219587, Time/step: 1.177249
2024-09-11 12:17:56,423:INFO: Epoch: 4/5, Step: 482/1406, Lr: 0.000000025-0.000024742, Loss: 0.236892, Time/step: 1.147977
2024-09-11 12:18:53,599:INFO: Epoch: 4/5, Step: 532/1406, Lr: 0.000000024-0.000023785, Loss: 0.265452, Time/step: 1.143507
2024-09-11 12:19:50,322:INFO: Epoch: 4/5, Step: 582/1406, Lr: 0.000000023-0.000022840, Loss: 0.317063, Time/step: 1.134454
2024-09-11 12:20:50,231:INFO: Epoch: 4/5, Step: 632/1406, Lr: 0.000000022-0.000021909, Loss: 0.278328, Time/step: 1.198156
2024-09-11 12:21:48,848:INFO: Epoch: 4/5, Step: 682/1406, Lr: 0.000000021-0.000020992, Loss: 0.268213, Time/step: 1.172323
2024-09-11 12:22:46,941:INFO: Epoch: 4/5, Step: 732/1406, Lr: 0.000000020-0.000020089, Loss: 0.330544, Time/step: 1.161857
2024-09-11 12:23:45,321:INFO: Epoch: 4/5, Step: 782/1406, Lr: 0.000000019-0.000019201, Loss: 0.334757, Time/step: 1.167573
2024-09-11 12:24:41,771:INFO: Epoch: 4/5, Step: 832/1406, Lr: 0.000000018-0.000018329, Loss: 0.250586, Time/step: 1.128990
2024-09-11 12:25:39,313:INFO: Epoch: 4/5, Step: 882/1406, Lr: 0.000000017-0.000017472, Loss: 0.325300, Time/step: 1.150819
2024-09-11 12:26:37,472:INFO: Epoch: 4/5, Step: 932/1406, Lr: 0.000000017-0.000016632, Loss: 0.276501, Time/step: 1.163164
2024-09-11 12:27:35,620:INFO: Epoch: 4/5, Step: 982/1406, Lr: 0.000000016-0.000015808, Loss: 0.352742, Time/step: 1.162926
2024-09-11 12:28:34,664:INFO: Epoch: 4/5, Step: 1032/1406, Lr: 0.000000015-0.000015002, Loss: 0.431708, Time/step: 1.180861
2024-09-11 12:29:32,815:INFO: Epoch: 4/5, Step: 1082/1406, Lr: 0.000000014-0.000014213, Loss: 0.336005, Time/step: 1.162972
2024-09-11 12:30:31,357:INFO: Epoch: 4/5, Step: 1132/1406, Lr: 0.000000013-0.000013442, Loss: 0.268377, Time/step: 1.170832
2024-09-11 12:31:29,788:INFO: Epoch: 4/5, Step: 1182/1406, Lr: 0.000000013-0.000012689, Loss: 0.211405, Time/step: 1.168597
2024-09-11 12:32:28,319:INFO: Epoch: 4/5, Step: 1232/1406, Lr: 0.000000012-0.000011954, Loss: 0.189918, Time/step: 1.170595
2024-09-11 12:33:26,477:INFO: Epoch: 4/5, Step: 1282/1406, Lr: 0.000000011-0.000011239, Loss: 0.411701, Time/step: 1.163149
2024-09-11 12:34:24,736:INFO: Epoch: 4/5, Step: 1332/1406, Lr: 0.000000011-0.000010543, Loss: 0.211530, Time/step: 1.165169
2024-09-11 12:35:20,891:INFO: Epoch: 4/5, Step: 1382/1406, Lr: 0.000000010-0.000009867, Loss: 0.239675, Time/step: 1.123085
2024-09-11 12:35:45,240:INFO: Epoch 4/5 Finished, Train Loss: 0.283641
2024-09-11 12:35:47,736:INFO: Model saved to logs/msrvtt/seqTransf_vit32/pytorch_model.bin.3
2024-09-11 12:35:47,736:INFO: Optimizer saved to logs/msrvtt/seqTransf_vit32/pytorch_opt.bin.3
2024-09-11 12:35:47,742:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-11 12:35:47,742:WARNING: sentence num: 1000, video num: 1000
2024-09-11 12:36:43,564:INFO: before reshape, sim matrix size: 1000 x 1000
2024-09-11 12:36:43,586:INFO: after reshape, sim matrix size: 1000 x 1 x 1000
2024-09-11 12:36:43,863:INFO: Text-to-Video:
2024-09-11 12:36:43,863:INFO: 	>>>  R@1: 41.9 - R@5: 71.1 - R@10: 81.6 - Median R: 2.0 - Mean R: 14.9
2024-09-11 12:36:43,863:INFO: Video-to-Text:
2024-09-11 12:36:43,863:INFO: 	>>>  V2T$R@1: 41.2 - V2T$R@5: 68.9 - V2T$R@10: 80.3 - V2T$Median R: 2.0 - V2T$Mean R: 11.9
2024-09-11 12:36:43,866:INFO: The best model is: logs/msrvtt/seqTransf_vit32/pytorch_model.bin.1, the R1 is: 43.0000
2024-09-11 12:37:20,889:INFO: Epoch: 5/5, Step: 26/1406, Lr: 0.000000009-0.000009210, Loss: 0.221920, Time/step: 0.735929
2024-09-11 12:38:18,527:INFO: Epoch: 5/5, Step: 76/1406, Lr: 0.000000009-0.000008575, Loss: 0.229635, Time/step: 1.152748
2024-09-11 12:39:16,588:INFO: Epoch: 5/5, Step: 126/1406, Lr: 0.000000008-0.000007959, Loss: 0.123964, Time/step: 1.161189
2024-09-11 12:40:14,478:INFO: Epoch: 5/5, Step: 176/1406, Lr: 0.000000007-0.000007365, Loss: 0.210546, Time/step: 1.157789
2024-09-11 12:41:14,031:INFO: Epoch: 5/5, Step: 226/1406, Lr: 0.000000007-0.000006792, Loss: 0.198999, Time/step: 1.191046
2024-09-11 12:42:12,101:INFO: Epoch: 5/5, Step: 276/1406, Lr: 0.000000006-0.000006241, Loss: 0.220961, Time/step: 1.161394
2024-09-11 12:43:07,489:INFO: Epoch: 5/5, Step: 326/1406, Lr: 0.000000006-0.000005711, Loss: 0.249831, Time/step: 1.107749
2024-09-11 12:44:06,638:INFO: Epoch: 5/5, Step: 376/1406, Lr: 0.000000005-0.000005204, Loss: 0.226721, Time/step: 1.182962
2024-09-11 12:45:03,914:INFO: Epoch: 5/5, Step: 426/1406, Lr: 0.000000005-0.000004719, Loss: 0.238918, Time/step: 1.145506
2024-09-11 12:46:03,571:INFO: Epoch: 5/5, Step: 476/1406, Lr: 0.000000004-0.000004256, Loss: 0.189477, Time/step: 1.193131
2024-09-11 12:47:02,574:INFO: Epoch: 5/5, Step: 526/1406, Lr: 0.000000004-0.000003817, Loss: 0.289799, Time/step: 1.180049
2024-09-11 12:47:59,541:INFO: Epoch: 5/5, Step: 576/1406, Lr: 0.000000003-0.000003400, Loss: 0.336074, Time/step: 1.139323
2024-09-11 12:48:57,607:INFO: Epoch: 5/5, Step: 626/1406, Lr: 0.000000003-0.000003007, Loss: 0.239341, Time/step: 1.161297
2024-09-11 12:49:55,225:INFO: Epoch: 5/5, Step: 676/1406, Lr: 0.000000003-0.000002637, Loss: 0.218527, Time/step: 1.152347
2024-09-11 12:50:52,949:INFO: Epoch: 5/5, Step: 726/1406, Lr: 0.000000002-0.000002291, Loss: 0.280335, Time/step: 1.154458
2024-09-11 12:51:52,013:INFO: Epoch: 5/5, Step: 776/1406, Lr: 0.000000002-0.000001969, Loss: 0.273499, Time/step: 1.181273
2024-09-11 12:52:49,556:INFO: Epoch: 5/5, Step: 826/1406, Lr: 0.000000002-0.000001670, Loss: 0.153287, Time/step: 1.150856
2024-09-11 12:53:48,454:INFO: Epoch: 5/5, Step: 876/1406, Lr: 0.000000001-0.000001396, Loss: 0.207462, Time/step: 1.177946
2024-09-11 12:54:45,808:INFO: Epoch: 5/5, Step: 926/1406, Lr: 0.000000001-0.000001146, Loss: 0.224961, Time/step: 1.147065
2024-09-11 12:55:42,183:INFO: Epoch: 5/5, Step: 976/1406, Lr: 0.000000001-0.000000920, Loss: 0.260291, Time/step: 1.127470
2024-09-11 12:56:39,919:INFO: Epoch: 5/5, Step: 1026/1406, Lr: 0.000000001-0.000000719, Loss: 0.279695, Time/step: 1.154690
2024-09-11 12:57:38,057:INFO: Epoch: 5/5, Step: 1076/1406, Lr: 0.000000001-0.000000543, Loss: 0.190627, Time/step: 1.162735
2024-09-11 12:58:36,266:INFO: Epoch: 5/5, Step: 1126/1406, Lr: 0.000000000-0.000000391, Loss: 0.244554, Time/step: 1.164148
2024-09-11 12:59:33,857:INFO: Epoch: 5/5, Step: 1176/1406, Lr: 0.000000000-0.000000264, Loss: 0.313019, Time/step: 1.151812
2024-09-11 13:00:32,459:INFO: Epoch: 5/5, Step: 1226/1406, Lr: 0.000000000-0.000000162, Loss: 0.272206, Time/step: 1.172005
2024-09-11 13:01:30,259:INFO: Epoch: 5/5, Step: 1276/1406, Lr: 0.000000000-0.000000084, Loss: 0.296525, Time/step: 1.155975
2024-09-11 13:02:28,616:INFO: Epoch: 5/5, Step: 1326/1406, Lr: 0.000000000-0.000000032, Loss: 0.230413, Time/step: 1.167126
2024-09-11 13:03:26,984:INFO: Epoch: 5/5, Step: 1376/1406, Lr: 0.000000000-0.000000004, Loss: 0.220403, Time/step: 1.167342
2024-09-11 13:03:59,563:INFO: Epoch 5/5 Finished, Train Loss: 0.238601
2024-09-11 13:04:01,535:INFO: Model saved to logs/msrvtt/seqTransf_vit32/pytorch_model.bin.4
2024-09-11 13:04:01,535:INFO: Optimizer saved to logs/msrvtt/seqTransf_vit32/pytorch_opt.bin.4
2024-09-11 13:04:01,542:WARNING: Eval under the multi-sentence per video clip setting.
2024-09-11 13:04:01,542:WARNING: sentence num: 1000, video num: 1000
2024-09-11 13:04:44,412:INFO: before reshape, sim matrix size: 1000 x 1000
2024-09-11 13:04:44,440:INFO: after reshape, sim matrix size: 1000 x 1 x 1000
2024-09-11 13:04:44,724:INFO: Text-to-Video:
2024-09-11 13:04:44,724:INFO: 	>>>  R@1: 41.8 - R@5: 70.2 - R@10: 81.5 - Median R: 2.0 - Mean R: 15.0
2024-09-11 13:04:44,724:INFO: Video-to-Text:
2024-09-11 13:04:44,724:INFO: 	>>>  V2T$R@1: 41.5 - V2T$R@5: 68.7 - V2T$R@10: 79.7 - V2T$Median R: 2.0 - V2T$Mean R: 12.2
2024-09-11 13:04:44,727:INFO: The best model is: logs/msrvtt/seqTransf_vit32/pytorch_model.bin.1, the R1 is: 43.0000
